name: Project 4 ‚Äì Automated Tests

on:
  push:
    paths:
      - "projects/project-4/**"

jobs:
  grade-project:
    runs-on: ubuntu-latest
    timeout-minutes: 25

    env:
      PROJECT_ROOT: projects/project-4/assignment

    defaults:
      run:
        working-directory: ${{ env.PROJECT_ROOT }}

    steps:
      - name: üßæ Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: üêç Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: üì¶ Install dependencies
        run: |
          python -m pip install --upgrade pip wheel
          pip install -r requirements.txt || pip install pandas rdflib pyshacl python-dateutil

      # -------------------------------------------------------------
      # (1) ETL validation
      # -------------------------------------------------------------
  
      - name: üß™ Run ETL
        run: python src/scripts/normalize_readings.py

      - name: ‚úÖ Check ETL script uses pandas
        shell: bash
        run: |
          grep -E '^\s*import\s+pandas\s+as\s+pd' src/scripts/normalize_readings.py >/dev/null || {
            echo "‚ùå ETL script must import pandas as pd (per guide)."; exit 1; }
          echo "‚úÖ pandas import found."

      - name: ‚úÖ Validate canonical CSV schema & content
        run: |
          python - << 'PY'
          import re, sys
          from pathlib import Path
          import pandas as pd

          CSV = Path("src/data/readings_normalized.csv")
          assert CSV.exists(), "‚ùå Missing src/data/readings_normalized.csv"

          # Schema check
          df = pd.read_csv(CSV, dtype=str, keep_default_na=False)
          exp_cols = ["artifact_id","sdc_kind","unit_label","value","timestamp"]
          assert list(df.columns) == exp_cols, f"‚ùå Bad header. Got {list(df.columns)}"

          # Empty?
          assert len(df) > 0, "‚ùå CSV has no data rows."

          # Trim & basic NA handling
          for c in exp_cols:
            df[c] = df[c].astype(str).str.strip()
          assert not (df[exp_cols].eq("").any().any()), "‚ùå Blank fields present in canonical columns."

          # 1) value must be numeric for ALL rows
          try:
            vals = pd.to_numeric(df["value"], errors="coerce")
          except Exception as e:
            raise AssertionError(f"‚ùå 'value' column not numeric: {e}")
          assert vals.notna().all(), "‚ùå Non-numeric values found in 'value'."

          # 2) timestamp must be ISO-8601 UTC (Z)
          # Accept formats like 2025-10-16T12:00:00Z or with fractional seconds.
          iso_utc = re.compile(r'^\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}(?:\.\d+)?Z$')
          bad_ts = df.loc[~df["timestamp"].apply(lambda s: bool(iso_utc.match(s)))]
          assert bad_ts.empty, f"‚ùå Non-UTC or non-ISO timestamps: {bad_ts['timestamp'].head(5).tolist()}"

          # 3) unit_label normalization: forbid common unnormalized forms from the guide
          # (You may expand this list as needed.)
          forbidden = {"celsius","fahrenheit","kilogram","meter","metre","¬∞c","¬∞f","kg "," m "," psi "," kpa "}
          # normalize to simple lower/trim for comparison
          def norm(s): return s.lower().strip()
          offenders = df[df["unit_label"].apply(norm).isin({x.strip() for x in forbidden})]
          assert offenders.empty, f"‚ùå Unnormalized unit labels found: {offenders['unit_label'].unique().tolist()}"

          print("‚úÖ ETL CSV satisfies ETL_Guide.md: schema, numeric values, ISO-UTC timestamps, normalized units.")
          PY

      # -------------------------------------------------------------
      # (2) RDF build validation
      # -------------------------------------------------------------

      - name: üß± Build RDF (RDFlib)
        run: python src/scripts/measure_rdflib.py

      - name: ‚úÖ Validate design pattern uses EXACT IRIs (ignore value/time)
        run: |
          python - << 'PY'
          from rdflib import Graph
          from pathlib import Path

          TTL = Path("src/measure_cco.ttl")
          assert TTL.exists(), "‚ùå src/measure_cco.ttl not found"
          g = Graph(); g.parse(TTL, format="turtle")
          print(f"[ttl] triples: {len(g)}")

          # Exact IRIs to enforce
          IRI_SDC   = "http://purl.obolibrary.org/obo/BFO_0000020"
          IRI_ART   = "https://www.commoncoreontologies.org/ont00000995"
          IRI_MU    = "https://www.commoncoreontologies.org/ont00000120"
          IRI_MICE  = "https://www.commoncoreontologies.org/ont00001163"

          IRI_BEARER_OF   = "http://purl.obolibrary.org/obo/BFO_0000196"
          IRI_IS_MEASURE_OF = "https://www.commoncoreontologies.org/ont00001966"
          IRI_USES_MU       = "https://www.commoncoreontologies.org/ont00001863"

          # 1) Ensure at least one of each type appears using the EXACT class IRIs
          q_types = f"""
          SELECT
            (COUNT(DISTINCT ?a) AS ?A)
            (COUNT(DISTINCT ?s) AS ?S)
            (COUNT(DISTINCT ?m) AS ?M)
            (COUNT(DISTINCT ?u) AS ?U)
          WHERE {{
            OPTIONAL {{ ?a a <{IRI_ART}> . }}
            OPTIONAL {{ ?s a <{IRI_SDC}> . }}
            OPTIONAL {{ ?m a <{IRI_MICE}> . }}
            OPTIONAL {{ ?u a <{IRI_MU}> . }}
          }}
          """
          A,S,M,U = [int(x) for x in list(g.query(q_types))[0]]
          assert all(v>0 for v in (A,S,M,U)), f"‚ùå Missing required typed nodes: Artifact={A}, SDC={S}, MICE={M}, MU={U}"
          print(f"‚úÖ Types present with exact IRIs: Artifact={A}, SDC={S}, MICE={M}, MU={U}")

          # 2) Ensure at least one complete pattern exists using ONLY the exact property IRIs
          q_pattern_strict = f"""
          ASK {{
            ?a a <{IRI_ART}> ;
               <{IRI_BEARER_OF}> ?sdc .
            ?sdc a <{IRI_SDC}> .

            ?m a <{IRI_MICE}> ;
               <{IRI_IS_MEASURE_OF}> ?sdc ;
               <{IRI_USES_MU}> ?u .

            ?u a <{IRI_MU}> .
          }}
          """
          assert bool(g.query(q_pattern_strict).askAnswer), "‚ùå No complete pattern found using the exact property IRIs."
          print("‚úÖ Complete pattern found with exact property IRIs.")

          # 3) Optional: verify every MICE uses the exact property IRIs (no alternative predicates)
          #    If you only need 'at least one' instance, comment this block out.
          q_all_mice_ok = f"""
          SELECT (COUNT(*) AS ?n_bad)
          WHERE {{
            ?m a <{IRI_MICE}> .
            # Missing required links with the exact IRIs?
            FILTER NOT EXISTS {{ ?m <{IRI_IS_MEASURE_OF}> ?sdc . ?sdc a <{IRI_SDC}> . }}
            UNION
            {{ ?m a <{IRI_MICE}> .
               FILTER NOT EXISTS {{ ?m <{IRI_USES_MU}> ?u . ?u a <{IRI_MU}> . }} }}
          }}
          """
          n_bad = int(list(g.query(q_all_mice_ok))[0][0])
          assert n_bad == 0, f"‚ùå Some MICE are missing required links with the exact IRIs (count={n_bad})."
          print("‚úÖ All MICE use exact IRIs for 'is measure of' and 'uses measurement unit'.")

          print("‚úÖ RDF passes exact-IRI checks for the measurement design pattern.")
          PY

      # -------------------------------------------------------------
      # (3) SPARQL queries validation
      # -------------------------------------------------------------
      - name: ‚úÖ Check SPARQL queries
        run: |
          python - << 'PY'
          from pathlib import Path
          from rdflib import Graph
          p = Path("src/sparql")
          assert p.exists(), "‚ùå src/sparql folder not found"
          files = sorted(p.glob("*.rq"))
          assert len(files) == 8, f"‚ùå Expected 8 .rq files, found {len(files)}"
          g = Graph()
          for f in files:
            try:
              list(g.query(f.read_text()))
            except Exception as e:
              raise AssertionError(f"‚ùå Invalid SPARQL query: {f.name} ({e})")
          print("‚úÖ All SPARQL queries parsed successfully.")
          PY

      # -------------------------------------------------------------
      # (4) SHACL validation
      # -------------------------------------------------------------
      - name: ‚úÖ Check SHACL shapes
        run: |
          python - << 'PY'
          from pathlib import Path
          from rdflib import Graph, Namespace, RDF
          SH = Namespace("http://www.w3.org/ns/shacl#")
          shapes_file = Path("src/cco_shapes.ttl")
          assert shapes_file.exists(), "‚ùå SHACL file missing: src/cco_shapes.ttl"
          g = Graph(); g.parse(shapes_file, format="turtle")
          nodes = set(g.subjects(RDF.type, SH.NodeShape))
          props = set(g.subjects(RDF.type, SH.PropertyShape))
          total = len(nodes | props)
          assert total >= 8, f"‚ùå Expected ‚â•8 SHACL shapes, found {total}"
          print(f"‚úÖ SHACL shapes OK ({total} total).")
          PY

      # -------------------------------------------------------------
      # (5) PR & workflow validation
      # -------------------------------------------------------------
      - name: ‚úÖ Check sensor_C.csv
        run: test -f src/data/sensor_C.csv || (echo "‚ùå Missing src/data/sensor_C.csv" && exit 1)

      - name: üîÅ Run ontology_workflow.yml
        run: |
          echo "‚úÖ All pre-checks passed. Your ontology_workflow.yml will trigger on future pushes to project-4."
