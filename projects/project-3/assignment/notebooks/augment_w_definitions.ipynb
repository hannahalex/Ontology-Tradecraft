{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edd14be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Optional, Dict\n",
    "import pandas as pd\n",
    "from rdflib import Graph, URIRef, Literal, Namespace\n",
    "from rdflib.namespace import RDFS, DCTERMS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f3a246",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Resolve paths relative to a notebook in notebooks/ (sibling to src/) ---\n",
    "NB_DIR  = Path.cwd().resolve()\n",
    "SRC_DIR = NB_DIR.parent / \"src\"\n",
    "if not SRC_DIR.exists():\n",
    "    alt = NB_DIR / \"src\"\n",
    "    if alt.exists():\n",
    "        SRC_DIR = alt\n",
    "if not SRC_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Could not find src/ near {NB_DIR}\")\n",
    "\n",
    "DATA_DIR = SRC_DIR / \"data\"\n",
    "if not DATA_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Could not find src/data/ at {DATA_DIR}\")\n",
    "\n",
    "print(\"SRC_DIR :\", SRC_DIR)\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "\n",
    "# --- Namespaces ---\n",
    "QUDT = Namespace(\"http://qudt.org/schema/qudt/\")\n",
    "SKOS = Namespace(\"http://www.w3.org/2004/02/skos/core#\")\n",
    "\n",
    "# --- Properties we’ll look in for textual definitions ---\n",
    "DEF_PROPS = [\n",
    "    SKOS.definition,\n",
    "    URIRef(\"http://purl.obolibrary.org/obo/IAO_0000115\"),  # IAO:definition\n",
    "    RDFS.comment,\n",
    "    DCTERMS.description,\n",
    "    URIRef(\"http://schema.org/description\"),\n",
    "    QUDT.definition,\n",
    "    QUDT.description,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beeb6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ttl_for(key: str) -> Optional[Path]:\n",
    "    # First try exact common filenames\n",
    "    candidates = [\n",
    "        SRC_DIR / f\"{key}.ttl\",\n",
    "        SRC_DIR / f\"{key}-core.ttl\",\n",
    "    ]\n",
    "    for c in candidates:\n",
    "        if c.exists():\n",
    "            return c\n",
    "    # Fallback: fuzzy search in SRC_DIR *.ttl\n",
    "    key_lower = key.lower()\n",
    "    for p in SRC_DIR.glob(\"*.ttl\"):\n",
    "        if key_lower in p.stem.lower():\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "# Define the ontology file map, auto-discovered\n",
    "ONTOLOGY_FILES: Dict[str, Path] = {}\n",
    "for k in [\"bfo-core\", \"ies\", \"ccom\", \"qudt\", \"ccot\", \"time\"]:\n",
    "    p = find_ttl_for(k)\n",
    "    if p:\n",
    "        ONTOLOGY_FILES[k] = p\n",
    "\n",
    "print(\"ONTOLOGY_FILES:\")\n",
    "for k, v in ONTOLOGY_FILES.items():\n",
    "    print(f\"  {k:>4} -> {v.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599eb201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(path: Path) -> Graph:\n",
    "    g = Graph()\n",
    "    g.parse(path)  # rdflib guesses turtle from extension\n",
    "    return g\n",
    "\n",
    "def _pick_best_literal_text(values) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    From a set/list of RDF literals, choose:\n",
    "      1) first with @en (any case), else\n",
    "      2) first with no language, else\n",
    "      3) the first value.\n",
    "    \"\"\"\n",
    "    vals = [v for v in values if isinstance(v, Literal)]\n",
    "    if not vals:\n",
    "        return None\n",
    "\n",
    "    def rank(lit: Literal) -> int:\n",
    "        if lit.language and str(lit.language).lower() == \"en\":\n",
    "            return 0\n",
    "        if lit.language is None:\n",
    "            return 1\n",
    "        return 2\n",
    "\n",
    "    vals.sort(key=rank)\n",
    "    return str(vals[0]).strip()\n",
    "\n",
    "def get_definition(g: Graph, iri: str) -> Optional[str]:\n",
    "    \"\"\"Return one textual definition for an IRI using DEF_PROPS, with language preference.\"\"\"\n",
    "    if not iri or not isinstance(iri, str):\n",
    "        return None\n",
    "    s = URIRef(iri)\n",
    "    hits = []\n",
    "    for prop in DEF_PROPS:\n",
    "        for o in g.objects(s, prop):\n",
    "            if isinstance(o, Literal):\n",
    "                hits.append(o)\n",
    "    return _pick_best_literal_text(hits)\n",
    "\n",
    "def discover_mapping_file(a: str, b: str) -> Optional[Path]:\n",
    "    \"\"\"\n",
    "    Return the path to 'a-b-structural-matches.xlsx' or 'b-a-structural-matches.xlsx'\n",
    "    if present in DATA_DIR; prefer a-b if both exist.\n",
    "    \"\"\"\n",
    "    first  = DATA_DIR / f\"{a}-{b}-structural-matches.xlsx\"\n",
    "    second = DATA_DIR / f\"{b}-{a}-structural-matches.xlsx\"\n",
    "    if first.exists():\n",
    "        return first\n",
    "    if second.exists():\n",
    "        return second\n",
    "    return None\n",
    "\n",
    "def find_iri_columns(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Heuristic: pick the first two columns whose names contain 'iri' (case-insensitive).\n",
    "    Falls back to ('left_iri', 'right_iri') or ('iri_left','iri_right') if present.\n",
    "    \"\"\"\n",
    "    cols = [c for c in df.columns if \"iri\" in c.lower()]\n",
    "    if len(cols) >= 2:\n",
    "        return cols[0], cols[1]\n",
    "    for pair in ((\"left_iri\", \"right_iri\"), (\"iri_left\", \"iri_right\")):\n",
    "        if all(c in df.columns for c in pair):\n",
    "            return pair\n",
    "    raise ValueError(\n",
    "        \"Could not detect two IRI columns in the mapping file. \"\n",
    "        f\"Columns present: {list(df.columns)}\"\n",
    "    )\n",
    "\n",
    "def augment_with_definitions(mapping_path: Path, left_key: str, right_key: str) -> Path:\n",
    "    \"\"\"\n",
    "    Load a mapping Excel, look up definitions for left/right IRIs using the\n",
    "    ontology TTLs for left_key/right_key (from ONTOLOGY_FILES), then write\n",
    "    '*-with-defs.xlsx' alongside it with columns:\n",
    "      - left_definition\n",
    "      - right_definition\n",
    "    \"\"\"\n",
    "    # Ensure the TTLs exist in the ONTOLOGY_FILES map\n",
    "    left_ttl  = ONTOLOGY_FILES.get(left_key)\n",
    "    right_ttl = ONTOLOGY_FILES.get(right_key)\n",
    "    if not left_ttl or not right_ttl:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Missing TTL path for '{left_key}' or '{right_key}'. \"\n",
    "            f\"Known: {ONTOLOGY_FILES}\"\n",
    "        )\n",
    "    if not left_ttl.exists() or not right_ttl.exists():\n",
    "        raise FileNotFoundError(f\"Missing TTL: {left_ttl} or {right_ttl}\")\n",
    "\n",
    "    print(f\"Reading {mapping_path.name} ...\")\n",
    "    df = pd.read_excel(mapping_path)\n",
    "    left_col, right_col = find_iri_columns(df)\n",
    "\n",
    "    # Load the ontologies\n",
    "    g_left  = load_graph(left_ttl)\n",
    "    g_right = load_graph(right_ttl)\n",
    "\n",
    "    # Add BOTH definition columns\n",
    "    df[\"left_definition\"]  = df[left_col].apply(lambda iri: get_definition(g_left, iri)  if pd.notna(iri) else None)\n",
    "    df[\"right_definition\"] = df[right_col].apply(lambda iri: get_definition(g_right, iri) if pd.notna(iri) else None)\n",
    "\n",
    "    out_path = mapping_path.with_name(mapping_path.stem + \"-with-defs.xlsx\")\n",
    "    df.to_excel(out_path, index=False)\n",
    "    print(f\"✅ Wrote: {out_path}\")\n",
    "    return out_path\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6c0217",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [(\"bfo-core\", \"ies\"), (\"ccom\", \"qudt\"), (\"ccot\", \"time\")]\n",
    "\n",
    "for (a, b) in pairs:\n",
    "    mp = discover_mapping_file(a, b)\n",
    "    if mp is None:\n",
    "        print(f\"⚠️  No mapping file found for {a}-{b} (or {b}-{a}) in {DATA_DIR}\")\n",
    "        continue\n",
    "    try:\n",
    "        augment_with_definitions(mp, a, b)\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Failed on {mp.name}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
